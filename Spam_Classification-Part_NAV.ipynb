{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff1e83d-32b6-4bd8-ba51-7c9d0eb9753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff42527-cd31-40c6-96ce-a8b4f9258faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The issue you're encountering is due to the fact that the sklearn package is deprecated. \n",
    "#Instead of pip install sklearn, you need to install scikit-learn directly. \n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac43f221-80d2-4530-88b8-a25dcdaf5892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd1e70-758a-4bea-af1e-96e63031f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The error you're encountering, UnicodeDecodeError, typically occurs when the CSV file contains characters that aren't properly decoded using the default encoding (utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e95b4d-ba8f-4f54-a8b4-7ca75134d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cebbe27e-42cb-4e96-9e9d-2598b1935958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('spam.csv', encoding='latin1') # #Latin-1 is occasionally, though imprecisely, referred to as Extended ASCII. This is because the first 128 characters of its set are identical to the US ASCII standard. \n",
    "df.shape                                             #The remainder of the set contains accented characters and symbols.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60891176-c278-462f-9bdc-f998e815f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                                                                                                                                v2 Unnamed: 2 Unnamed: 3 Unnamed: 4\n",
      "0   ham                                                   Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...        NaN        NaN        NaN\n",
      "1   ham                                                                                                                                     Ok lar... Joking wif u oni...        NaN        NaN        NaN\n",
      "2  spam       Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's        NaN        NaN        NaN\n",
      "3   ham                                                                                                                 U dun say so early hor... U c already then say...        NaN        NaN        NaN\n",
      "4   ham                                                                                                     Nah I don't think he goes to usf, he lives around here though        NaN        NaN        NaN\n",
      "5  spam              FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv        NaN        NaN        NaN\n",
      "6   ham                                                                                     Even my brother is not like to speak with me. They treat me like aids patent.        NaN        NaN        NaN\n",
      "7   ham  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune        NaN        NaN        NaN\n",
      "8  spam    WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.        NaN        NaN        NaN\n",
      "9  spam        Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030        NaN        NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "#Get shape and head\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa54da5-c90b-4286-a6af-cabf5c47b2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                                                                                                                                v2 Unnamed: 2 Unnamed: 3 Unnamed: 4\n",
       "0   ham                                                   Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...        NaN        NaN        NaN\n",
       "1   ham                                                                                                                                     Ok lar... Joking wif u oni...        NaN        NaN        NaN\n",
       "2  spam       Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's        NaN        NaN        NaN\n",
       "3   ham                                                                                                                 U dun say so early hor... U c already then say...        NaN        NaN        NaN\n",
       "4   ham                                                                                                     Nah I don't think he goes to usf, he lives around here though        NaN        NaN        NaN\n",
       "5  spam              FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv        NaN        NaN        NaN\n",
       "6   ham                                                                                     Even my brother is not like to speak with me. They treat me like aids patent.        NaN        NaN        NaN\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune        NaN        NaN        NaN\n",
       "8  spam    WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.        NaN        NaN        NaN\n",
       "9  spam        Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030        NaN        NaN        NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False) #True (default): Splits/wraps the DataFrame across multiple lines if it's too wide.\n",
    "                                                    #False: Displays the DataFrame in one continuous line, regardless of width.\n",
    "pd.set_option('max_colwidth',None)  #Setting max_colwidth to None removes this limit. This means Pandas will display the full content of each cell, regardless of how long the text is.\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd1c9b8-6b72-451a-97d2-2c2769935efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u. U have won the å£750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other suggestions?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                                                                                                                                               text Unnamed: 2 Unnamed: 3 Unnamed: 4\n",
       "0         ham                                                    Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...        NaN        NaN        NaN\n",
       "1         ham                                                                                                                                      Ok lar... Joking wif u oni...        NaN        NaN        NaN\n",
       "2        spam        Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's        NaN        NaN        NaN\n",
       "3         ham                                                                                                                  U dun say so early hor... U c already then say...        NaN        NaN        NaN\n",
       "4         ham                                                                                                      Nah I don't think he goes to usf, he lives around here though        NaN        NaN        NaN\n",
       "...       ...                                                                                                                                                                ...        ...        ...        ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u. U have won the å£750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.        NaN        NaN        NaN\n",
       "5568      ham                                                                                                                              Will Ì_ b going to esplanade fr home?        NaN        NaN        NaN\n",
       "5569      ham                                                                                                          Pity, * was in mood for that. So...any other suggestions?        NaN        NaN        NaN\n",
       "5570      ham                                      The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free        NaN        NaN        NaN\n",
       "5571      ham                                                                                                                                         Rofl. Its true to its name        NaN        NaN        NaN\n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'v1': 'category', 'v2': 'text'})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83eea622-1423-40bb-9cf5-43b1dc88cc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u. U have won the å£750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other suggestions?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                   text category\n",
       "0                                                       Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...      ham\n",
       "1                                                                                                                                         Ok lar... Joking wif u oni...      ham\n",
       "2           Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's     spam\n",
       "3                                                                                                                     U dun say so early hor... U c already then say...      ham\n",
       "4                                                                                                         Nah I don't think he goes to usf, he lives around here though      ham\n",
       "...                                                                                                                                                                 ...      ...\n",
       "5567  This is the 2nd time we have tried 2 contact u. U have won the å£750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.     spam\n",
       "5568                                                                                                                              Will Ì_ b going to esplanade fr home?      ham\n",
       "5569                                                                                                          Pity, * was in mood for that. So...any other suggestions?      ham\n",
       "5570                                      The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free      ham\n",
       "5571                                                                                                                                         Rofl. Its true to its name      ham\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf=df[['text', 'category']]\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ebc3ca-2f93-4158-8273-4be5a70c6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = [\n",
    "'the sky is blue',\n",
    "'sky is blue and sky is beautiful',\n",
    "'the beautiful sky is so blue',\n",
    "'i love blue cheese'\n",
    "]\n",
    "new_doc = ['loving this blue sky today']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04ce5e6-5d13-4f1c-b01a-fa97059ec695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams:\n",
      "['and' 'beautiful' 'blue' 'cheese' 'is' 'love' 'sky' 'so' 'the']\n",
      "[[0 0 1 0 1 0 1 0 1]\n",
      " [1 1 1 0 2 0 2 0 0]\n",
      " [0 1 1 0 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the corpus\n",
    "CORPUS = [\n",
    "    'the sky is blue',\n",
    "    'sky is blue and sky is beautiful',\n",
    "    'the beautiful sky is so blue',\n",
    "    'i love blue cheese'\n",
    "]\n",
    "\n",
    "#new_doc = ['loving this blue sky today']\n",
    "\n",
    "# Define a function to extract n-grams\n",
    "def extract_ngrams(corpus, ngram_range=(1,1)):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    \n",
    "    # Fit on corpus and transform both corpus and new document\n",
    "    X_corpus = vectorizer.fit_transform(corpus)\n",
    "    #X_new_doc = vectorizer.transform(new_doc)\n",
    "    \n",
    "    # Get feature names (n-grams)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Convert the results to arrays\n",
    "    corpus_ngrams = X_corpus.toarray()\n",
    "    #new_doc_ngrams = X_new_doc.toarray()\n",
    "    \n",
    "    return feature_names, corpus_ngrams\n",
    "\n",
    "# Unigrams (1-gram)\n",
    "unigrams, corpus_unigrams = extract_ngrams(CORPUS, ngram_range=(1, 1))\n",
    "print(\"Unigrams:\")\n",
    "print(unigrams)\n",
    "print(corpus_unigrams)\n",
    "#print(new_doc_unigrams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234367ba-cc7e-4efa-ab59-2b6956af9a39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_ngrams() got multiple values for argument 'ngram_range'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Bigrams (2-grams)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m corpus_bigrams, new_doc_bigrams \u001b[38;5;241m=\u001b[39m \u001b[43mextract_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCORPUS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngram_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBigrams:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#print(bigrams)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: extract_ngrams() got multiple values for argument 'ngram_range'"
     ]
    }
   ],
   "source": [
    "# Bigrams (2-grams)\n",
    "bigrams, corpus_bigrams, new_doc_bigrams = extract_ngrams(CORPUS, new_doc, ngram_range=(2, 2))\n",
    "print(\"\\nBigrams:\")\n",
    "print(bigrams)\n",
    "print(corpus_bigrams)\n",
    "print(new_doc_bigrams)\n",
    "\n",
    "# Trigrams (3-grams)\n",
    "trigrams, corpus_trigrams, new_doc_trigrams = extract_ngrams(CORPUS, new_doc, ngram_range=(3, 3))\n",
    "print(\"\\nTrigrams:\")\n",
    "print(trigrams)\n",
    "print(corpus_trigrams)\n",
    "print(new_doc_trigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df5af7f2-1eac-4bba-bee9-c551fe46f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 18 stored elements and shape (4, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 8)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 6)\t2\n",
      "  (1, 4)\t2\n",
      "  (1, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 7)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 3)\t1\n",
      "\n",
      "\n",
      " features names are:  ['and' 'beautiful' 'blue' 'cheese' 'is' 'love' 'sky' 'so' 'the']\n",
      "*********************************************************************\n",
      "\n",
      " features are  [[0 0 1 0 1 0 1 0 1]\n",
      " [1 1 1 0 2 0 2 0 0]\n",
      " [0 1 1 0 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 0 0 0]]\n",
      "\n",
      " features are\n",
      " [[0 0 1 0 1 0 1 0 1]\n",
      " [1 1 1 0 2 0 2 0 0]\n",
      " [0 1 1 0 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 0 0 0]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unigrams1 DataFrame:\n",
      "   and  beautiful  blue  cheese  is  love  sky  so  the\n",
      "0    0          0     1       0   1     0    1   0    1\n",
      "1    1          1     1       0   2     0    2   0    0\n",
      "2    0          1     1       0   1     0    1   1    1\n",
      "3    0          0     1       1   0     1    0   0    0\n",
      "\n",
      "\n",
      "Unigrams2 DataFrame:\n",
      "      N-gram  Corpus Count\n",
      "0        and             1\n",
      "1  beautiful             2\n",
      "2       blue             4\n",
      "3     cheese             1\n",
      "4         is             4\n",
      "5       love             1\n",
      "6        sky             4\n",
      "7         so             1\n",
      "8        the             2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the corpus and new document\n",
    "CORPUS = [\n",
    "    'the sky is blue',\n",
    "    'sky is blue and sky is beautiful',\n",
    "    'the beautiful sky is so blue',\n",
    "    'i love blue cheese'\n",
    "]\n",
    "\n",
    "new_doc = ['loving this blue sky today']\n",
    "\n",
    "# Define a function to extract n-grams and return them as a DataFrame\n",
    "def extract_ngrams_df(corpus, new_doc, ngram_range=(1,1)):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    \n",
    "    # Fit on corpus and transform both corpus and new document\n",
    "    X_corpus = vectorizer.fit_transform(corpus)\n",
    "    print(type(X_corpus))\n",
    "    print(X_corpus)\n",
    "    X_new_doc = vectorizer.transform(new_doc)\n",
    "    \n",
    "    # Get feature names (n-grams)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    print(\"\\n\\n features names are: \",feature_names)\n",
    "\n",
    "    features = X_corpus.toarray()           #toarray() and todense( ) are equivalent\n",
    "    # Convert the results to arrays\n",
    "    print(\"*********************************************************************\")\n",
    "    print(\"\\n features are \",X_corpus.todense()) # dense matrix representation\n",
    "    print(\"\\n features are\\n\",features) # dense matrix representation\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    corpus_ngrams = X_corpus.toarray().sum(axis=0)  # Sum counts across all corpus documents\n",
    "    #new_doc_ngrams = X_new_doc.toarray().flatten()  # Flatten the new document's array\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    df1 = pd.DataFrame(data=features,\n",
    "            columns=feature_names)\n",
    "    \n",
    "    df2 = pd.DataFrame({\n",
    "        'N-gram': feature_names,\n",
    "       'Corpus Count': corpus_ngrams,\n",
    "        \n",
    "     })\n",
    "\n",
    "    \n",
    "    \n",
    "    return df1, df2\n",
    "\n",
    "# Unigrams (1-gram)\n",
    "df_unigrams1, df_unigrams2 = extract_ngrams_df(CORPUS, new_doc, ngram_range=(1, 1))\n",
    "print(\"\\n\\nUnigrams1 DataFrame:\")\n",
    "print(df_unigrams1)\n",
    "print(\"\\n\\nUnigrams2 DataFrame:\")\n",
    "print(df_unigrams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254cace-0e9d-4bad-a27f-f73fff225a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_doc = vectorizer.transform(new_doc)\n",
    "    \n",
    "    # Get feature names (n-grams)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    print(\"\\n\\n features names are: \",feature_names)\n",
    "\n",
    "    features = X_corpus.toarray()           #toarray() and todense( ) are equivalent\n",
    "    # Convert the results to arrays\n",
    "    #print(\"\\n features are \",X_corpus.todense()) # dense matrix representation\n",
    "    print(\"\\n features are\\n\",features) # dense matrix representation\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    corpus_ngrams = X_corpus.toarray().sum(axis=0)  # Sum counts across all corpus documents\n",
    "    #new_doc_ngrams = X_new_doc.toarray().flatten()  # Flatten the new document's array\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    df1 = pd.DataFrame(data=features,\n",
    "            columns=feature_names)\n",
    "    \n",
    "    df2 = pd.DataFrame({\n",
    "        'N-gram': feature_names,\n",
    "       'Corpus Count': corpus_ngrams,\n",
    "        \n",
    "     })\n",
    "\n",
    "    \n",
    "    \n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0872288-5eda-4c7a-aa7d-384b76a8b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "  (0, 11)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 8)\t2\n",
      "  (1, 5)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 9)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 3)\t1\n",
      "\n",
      "\n",
      " features names are:  ['and sky' 'beautiful sky' 'blue and' 'blue cheese' 'is beautiful'\n",
      " 'is blue' 'is so' 'love blue' 'sky is' 'so blue' 'the beautiful'\n",
      " 'the sky']\n",
      "\n",
      " features are\n",
      " [[0 0 0 0 0 1 0 0 1 0 0 1]\n",
      " [1 0 1 0 1 1 0 0 2 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 1 1 1 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bigrams1 DataFrame:\n",
      "   and sky  beautiful sky  blue and  blue cheese  is beautiful  is blue  is so  love blue  sky is  so blue  the beautiful  the sky\n",
      "0        0              0         0            0             0        1      0          0       1        0              0        1\n",
      "1        1              0         1            0             1        1      0          0       2        0              0        0\n",
      "2        0              1         0            0             0        0      1          0       1        1              1        0\n",
      "3        0              0         0            1             0        0      0          1       0        0              0        0\n",
      "\n",
      "Bigrams2 DataFrame:\n",
      "           N-gram  Corpus Count\n",
      "0         and sky             1\n",
      "1   beautiful sky             1\n",
      "2        blue and             1\n",
      "3     blue cheese             1\n",
      "4    is beautiful             1\n",
      "5         is blue             2\n",
      "6           is so             1\n",
      "7       love blue             1\n",
      "8          sky is             4\n",
      "9         so blue             1\n",
      "10  the beautiful             1\n",
      "11        the sky             1\n"
     ]
    }
   ],
   "source": [
    "# Bigrams (2-grams)\n",
    "df_bigrams1, df_bigrams2 = extract_ngrams_df(CORPUS, new_doc, ngram_range=(2, 2))\n",
    "print(\"\\nBigrams1 DataFrame:\")\n",
    "print(df_bigrams1)\n",
    "\n",
    "print(\"\\nBigrams2 DataFrame:\")\n",
    "print(df_bigrams2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867243e-b370-4870-aad3-f419e7931834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigrams (3-grams)\n",
    "df_trigrams = extract_ngrams_df(CORPUS, new_doc, ngram_range=(3, 3))\n",
    "print(\"\\nTrigrams DataFrame:\")\n",
    "print(df_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e3e5dd-f188-43c4-8efa-2df7b2297bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[\n",
    "      [1, 1, 1, 1],  # Document 1\n",
    "      [0, 2, 1, 1],  # Document 2\n",
    "      [1, 1, 1, 1]   # Document 3\n",
    "   ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32bc05d3-9555-4497-88bc-726b8d08a0ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'torray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorray\u001b[49m()\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#will sum the counts for each unigram (column-wise) across all documents:\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'torray'"
     ]
    }
   ],
   "source": [
    "arr.torray().sum(axis=0) #will sum the counts for each unigram (column-wise) across all documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "725f1647-40c4-4aa9-a081-f446b70f4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t3\n",
      "  (1, 0)\t4\n",
      "  (2, 1)\t5\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Define non-zero values and their coordinates\n",
    "data = np.array([3, 4, 5])          # Non-zero values\n",
    "row_indices = np.array([0, 1, 2])   # Row indices\n",
    "col_indices = np.array([2, 0, 1])   # Column indices\n",
    "\n",
    "# Create a sparse matrix\n",
    "sparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(3, 3))\n",
    "\n",
    "# Display the sparse matrix\n",
    "print(sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d38b85b-121e-4708-ab9a-6c9fa91c0d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t3\n",
      "  (1, 0)\t4\n",
      "  (2, 1)\t5\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Define a dense 2D list (matrix)\n",
    "dense_array = [\n",
    "    [0, 0, 3],\n",
    "    [4, 0, 0],\n",
    "    [0, 5, 0]\n",
    "]\n",
    "\n",
    "# Create a sparse matrix\n",
    "sparse_matrix = csr_matrix(dense_array)\n",
    "\n",
    "# Display the sparse matrix\n",
    "print(sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2599693-b4cd-4eba-96c9-07ce76a36fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 3],\n",
       "       [4, 0, 0],\n",
       "       [0, 5, 0]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ae0cb57-4d53-4374-b09b-7287e442dcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f43b9-ea7e-40cc-b882-873a37069225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04fc900-93df-4fd4-b0a8-4da38ec9c86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('spam.csv', encoding='latin1') # #Latin-1 is occasionally, though imprecisely, referred to as Extended ASCII. This is because the first 128 characters of its set are identical to the US ASCII standard. \n",
    "df.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17756850-d89e-45b8-a06a-7e6a66a6dc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text category\n",
       "0     Go until jurong point, crazy.. Available only ...      ham\n",
       "1                         Ok lar... Joking wif u oni...      ham\n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...     spam\n",
       "3     U dun say so early hor... U c already then say...      ham\n",
       "4     Nah I don't think he goes to usf, he lives aro...      ham\n",
       "...                                                 ...      ...\n",
       "5567  This is the 2nd time we have tried 2 contact u...     spam\n",
       "5568              Will Ì_ b going to esplanade fr home?      ham\n",
       "5569  Pity, * was in mood for that. So...any other s...      ham\n",
       "5570  The guy did some bitching but I acted like i'd...      ham\n",
       "5571                         Rofl. Its true to its name      ham\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'v1': 'category', 'v2': 'text'})\n",
    "newdf=df[['text', 'category']]\n",
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1edc0-bba2-47d4-8e4b-bbba47633886",
   "metadata": {},
   "source": [
    "Step 2: Data Analysis<br>\n",
    "1. Check for Missing Values: It’s essential to check if there are any missing values in your DataFrame.\n",
    "2. Class Distribution: Check how many messages are \"ham\" and how many are \"spam.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78d23220-5bb4-49e4-a1cb-8ed33d0fb99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(newdf['text'].isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c0874c-a826-4600-b6e7-04ced61fe039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text        0\n",
      "category    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(newdf.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c2542cd-e508-4716-b560-0f3f0ba1c044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Class Distribution: Check how many messages are \"ham\" and how many are \"spam.\"\n",
    "print(df['category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7804ae32-b31e-44a5-9c04-6fadd0c057e6",
   "metadata": {},
   "source": [
    "1. Step 3: Text Preprocessing\n",
    "2. Before you can use this data for modeling, you typically need to preprocess the text data. Common steps include:\n",
    "\n",
    "3. Lowercasing\n",
    "4. Removing punctuation\n",
    "5. Removing stop words\n",
    "6. Tokenization\n",
    "7. Converting text to numerical features (e.g., using Bag of Words or TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49371974-3788-4404-b65c-c800cbadb1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s=r'\\n'\n",
    "print(s)\n",
    "t= '\\n'\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c61277b6-03aa-43ae-8318-888a1c2ab6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akhtar',\n",
       " 'age',\n",
       " 'is',\n",
       " '14',\n",
       " 'and',\n",
       " 'saeed',\n",
       " 'age',\n",
       " 'is',\n",
       " '15',\n",
       " 'are',\n",
       " 'friends',\n",
       " 'but',\n",
       " 'they',\n",
       " 'usuallydisagree',\n",
       " 'on',\n",
       " 'certain',\n",
       " 'matters']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='&&&&&akhtar age is 14 and??? saeed age is 15 are %%%friends but they usually++++++++disagree on certain matters'\n",
    "text1=re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "text1=text1.split(\" \")\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2286b8f3-b005-431d-a735-eef13973b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ef52445-332f-498b-9bf5-9795cae761a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0bff5fd0-fed9-4a01-a2d0-0748e2eb9e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akhtar',\n",
       " 'age',\n",
       " '14',\n",
       " 'saeed',\n",
       " 'age',\n",
       " '15',\n",
       " 'friends',\n",
       " 'usuallydisagree',\n",
       " 'certain',\n",
       " 'matters']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext=[x for x in text1 if x not in stop]\n",
    "cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07427ce1-7056-48a1-b6a8-0968ca83702a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WordListCorpusReader' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstopwords\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'WordListCorpusReader' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in stopwords:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ac13378-e9da-4f4c-86a3-01a3aff30acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akhtar age is 14 and 15\n"
     ]
    }
   ],
   "source": [
    "text= ['akhtar',  'age',  'is',  '14',  'and','15']\n",
    "print(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a413afc-3d08-4c70-b922-99f497e9308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                          text                                                                                                                             Cleaned_Text\n",
      "0                                              Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                       go jurong point crazy available bugis n great world la e buffet cine got amore wat\n",
      "1                                                                                                                                Ok lar... Joking wif u oni...                                                                                                                  ok lar joking wif u oni\n",
      "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's  free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questionstd txt ratetcs apply 08452810075over18s\n",
      "3                                                                                                            U dun say so early hor... U c already then say...                                                                                                      u dun say early hor u c already say\n",
      "4                                                                                                Nah I don't think he goes to usf, he lives around here though                                                                                              nah dont think goes usf lives around though\n",
      "5         FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv                                                  freemsg hey darling 3 weeks word back id like fun still tb ok xxx std chgs send 150 rcv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.split(\" \")\n",
    "    \n",
    "    text = [x for x in text if x not in stop]\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Apply preprocessing to the Message column\n",
    "df['Cleaned_Text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Display the cleaned messages\n",
    "print(df[['text', 'Cleaned_Text']].head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e45bdc5-2586-4149-9930-aa6531d5a323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         Cleaned_Text\n",
      "0  go jurong point crazy available bugis n great world la e buffet cine got amore wat\n",
      "1                                                             ok lar joking wif u oni\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned messages\n",
    "print(df[['Cleaned_Text']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23c755-cbdc-4f16-92b8-5c275ba0140e",
   "metadata": {},
   "source": [
    "1. Step 4: Feature Extraction\n",
    "2. You can use CountVectorizer to convert the cleaned text data into numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5ca5de0-d2b3-40f9-ba57-683c32dbfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and labels\n",
    "X = df['Cleaned_Text']\n",
    "y = df['category']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "455a6a80-55c8-44bd-aa31-c1a5fa06c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d73bc357-6842-4bbf-b0fc-64e2ced38221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 8218)\n",
      "(1115, 8218)\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "print(X_test_vectorized.shape)\n",
    "print(X_train_vectorized[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4f8e036-1029-47bd-ad7a-80fabcfe6c2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Vectorize the text data with bigrams\u001b[39;00m\n\u001b[0;32m      2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# Extract bigrams\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[0;32m      4\u001b[0m X_test_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_vectorized\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Vectorize the text data with bigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))  # Extract bigrams\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "print(X_test_vectorized.shape)\n",
    "\n",
    "# Vectorize the text data with trigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(3, 3))  # Extract trigrams\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "print(X_test_vectorized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199320e8-4d1c-4828-90f8-ef098df7876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vectorize the text data with unigrams, bigrams, and trigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))  # Extract unigrams, bigrams, and trigrams\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "print(X_test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf5e20-7c20-40ae-81e0-98fbfd46e211",
   "metadata": {},
   "source": [
    "Step 5: Building a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1cca14-d1b5-4630-92ec-7889537d7560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
